<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Unbelievable Usefulness of Batchnorm | Fengyang Zhang&#39;s blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="Here’s some basic and shallow experience with batchnorm, an incredibly powerful weapon in deep neural networks, and some pitfalls in using it with tensorflow.">
<meta property="og:type" content="article">
<meta property="og:title" content="Unbelievable Usefulness of Batchnorm">
<meta property="og:url" content="http://freydom.com/2017/03/04/experience-with-batchnorm/index.html">
<meta property="og:site_name" content="Fengyang Zhang's blog">
<meta property="og:description" content="Here’s some basic and shallow experience with batchnorm, an incredibly powerful weapon in deep neural networks, and some pitfalls in using it with tensorflow.">
<meta property="og:image" content="http://freydom.com/pic/2017-03-04-experience-with-batchnorm/layer_inputs.png">
<meta property="og:updated_time" content="2017-03-25T08:00:03.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Unbelievable Usefulness of Batchnorm">
<meta name="twitter:description" content="Here’s some basic and shallow experience with batchnorm, an incredibly powerful weapon in deep neural networks, and some pitfalls in using it with tensorflow.">
<meta name="twitter:image" content="http://freydom.com/pic/2017-03-04-experience-with-batchnorm/layer_inputs.png">
  
    <link rel="alternate" href="https://github.com/fengyangzhang" title="Fengyang Zhang&#39;s blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.ico">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Fengyang Zhang&#39;s blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">I&#39;m a Master of Computer Science student in UVa, my study and research interest lies in Computer Vision and Machine Learning.</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About</a>
        
          <a class="main-nav-link" href="/tags/Technology/">Technology</a>
        
      </nav>
      <nav id="sub-nav">
      <a class="nav-icon-social" href="https://github.com/FengyangZhang" title="Github" target="_blank"><img src="/css/images/github.png"></a>
        
          <!-- <a id="nav-rss-link" class="nav-icon" href="https://github.com/fengyangzhang" title="My Github"></a> -->
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-experience-with-batchnorm" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/04/experience-with-batchnorm/" class="article-date">
  <time datetime="2017-03-05T01:41:46.000Z" itemprop="datePublished">2017-03-04</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Unbelievable Usefulness of Batchnorm
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Here’s some basic and shallow experience with batchnorm, an incredibly powerful weapon in deep neural networks, and some pitfalls in using it with tensorflow.<br><a id="more"></a><br>Proposed by <a href="https://arxiv.org/abs/1502.03167" target="_blank" rel="external">Szegedy et al. in 2015</a>, batchnorm has since gain its popularity among deep learning architectures. It was designed to address the problem of killed gradients in deep networks. Before this technique came out, training deep networks is a really tricky task, because the gradients are easily killed in the last layers.<br>Take a simple example as $y = x .* w + b$, which denotes a single fully-connected layer. In the beginning we use small random numbers to initialize the weights $w$, and when the layers get stacked up, the output $y$ in each layer get smaller and smaller, thus, in the backward pass, the gradient of $w$, which is some coeffient times $x$, will be very small, and even zero in the first layers.<br>So what kinds of input does the layers want? A good answer may be <strong>unit gaussian</strong>, like this:<br><img src="/pic/2017-03-04-experience-with-batchnorm/layer_inputs.png" alt="a desirable layer inputs"><br>So what the batchnorm layer actually does is to add a step to transform the data to unit gaussian distribution. More intuitively as follows:<br>$$<br>\Large \hat{x}^{(k)}=\frac{x^{(k)}-E[x^{(k)}]}{ \sqrt{VAR[x^{(k)}]} }<br>$$<br>Actually when you implements this transformation, a little coefficient $\epsilon$ is added in the denominator to avoid devided by zero. The reason you can do this is, that this function is differenciable, and you can apply learnable coefficients on $E$ and $VAR$, so that the network can learn to do little in these layers or do a lot depends on the need.<br>I encounterd the problem of killed gradients in a task, whose model is an 11-layered CNN-based model. At first I find that the network learns nothing after several batches, so obviously the gradients are killed. I then applied batchnorm to some layers, and the network start to learn as a charm.<br>But still there are things to be careful with, when you actually implement batchnorm. </p>
<pre><code>def batchnorm_for_affine(layer):
    D = layer.get_shape()[-1]
    scale = tf.Variable(tf.ones([D]))
    beta = tf.Variable(tf.zeros([D]))
    pop_mean = tf.Variable(tf.zeros([D]), trainable=False)
    pop_var = tf.Variable(tf.ones([D]), trainable=False)
    epsilon = 1e-3
    decay = 0.999

    if(args[&quot;test_mode&quot;] &lt;= 0):
        batch_mean, batch_var = tf.nn.moments(layer,[0])
        train_mean = tf.assign(pop_mean,
            pop_mean * decay + batch_mean * (1 - decay))
        train_var = tf.assign(pop_var,
            pop_var * decay + batch_var * (1 - decay))
        with tf.control_dependencies([train_mean, train_var]):
            return tf.nn.batch_normalization(layer,
                batch_mean, batch_var, beta, scale, epsilon)
    else:
        return tf.nn.batch_normalization(layer,
            pop_mean, pop_var, beta, scale, epsilon)
</code></pre><p>Here scale and beta are the learnable parameters. First you need to have two sets of means and vars, because at testtime, you cannot use the same procedure as training time, or you get zero outputs. So you need to set a running mean and var, which you will use at testtime.<br>Second thing is, the batchnorm function is different for different kinds of layers. For example you need to flatten the matrix when you are applying batchnorm to output of a CNN layer. Because batchnorm is doing normalization on your mini-batch, more specifically normalize every individual features according to others in the batch.</p>
<p>So, when you are using random small number initialization, or simpel Xavier initialization, make smart use of batchnorm is almost always a good choice. You can also use more intricate initialization, and use activation functions other than RELU, say leaky RELU or something else.</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://freydom.com/2017/03/04/experience-with-batchnorm/" data-id="cjo8zj99u000iysm2qjft1wo5" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Technology/">Technology</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2016/12/26/Notes-on-three-Handwritten-Chinese-Char-Rec-Models/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Notes on three Handwritten Chinese Character Recognition Models</div>
    </a>
  
</nav>

  
</article>


        

<div id="google_translate_element"></div><script type="text/javascript">
function googleTranslateElementInit() {
  new google.translate.TranslateElement({pageLanguage: 'en', includedLanguages: 'en,zh-CN'}, 'google_translate_element');
}
</script><script type="text/javascript" src="//translate.google.com/translate_a/element.js?cb=googleTranslateElementInit"></script>
 </section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Technology/" style="font-size: 10px;">Technology</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">March 2017</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/12/">December 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/10/">October 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/09/">September 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/08/">August 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/07/">July 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/05/">May 2016</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/03/04/experience-with-batchnorm/">Unbelievable Usefulness of Batchnorm</a>
          </li>
        
          <li>
            <a href="/2016/12/26/Notes-on-three-Handwritten-Chinese-Char-Rec-Models/">Notes on three Handwritten Chinese Character Recognition Models</a>
          </li>
        
          <li>
            <a href="/2016/12/22/Notes-on-Chinese-Char-Recog-using-DL/">Handwritten Chinese Character Recognition using DL, Overview</a>
          </li>
        
          <li>
            <a href="/2016/12/15/ThreeLayerBP/">ThreeLayerBP</a>
          </li>
        
          <li>
            <a href="/2016/11/21/BUPTCNLogin/">BUPTCNLogin</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner" style="text-align:center;">
	  <table width="100%" border="0">
        <tr>
          <td style="text-align:left">
            Copyright &copy; 2014-2018 Fengyang Zhang &nbsp; &nbsp;
            Powered by <a href="http://hexo.io/" target="_blank">Hexo</a><br>
	        Theme Landscape
		  </td>
		  <td style="text-align:right">
		    <div style="font-family: FontAwesome;font-size: 20px;">
		    <a href="http://weibo.com/2826643047" title="微博" target="_blank">&#61834;</a>&nbsp;	
			<a href="https://github.com/FengyangZhang" title="GitHub" target="_blank">&#61595;</a>&nbsp;
			</div><br>
		  </td>
        </tr>
      </table>
    </div>
</div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About</a>
  
    <a href="/tags/Technology/" class="mobile-nav-link">Technology</a>
  
</nav>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>


<script type="text/x-mathjax-config">
    MathJax.Hub.Config({"HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"], linebreaks: { automatic:true }, EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50) },
        tex2jax: { inlineMath: [ ["$", "$"], ["\\(","\\)"] ], processEscapes: true, ignoreClass: "tex2jax_ignore|dno",skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']},
        TeX: {  noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } }, Macros: { href: "{}" } },
        messageStyle: "none"
    }); 
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </div>
</body>
</html>